# Legal Text Hallucination Detection System

An Applied Natural Language Processing project focused on detecting hallucinations in AI-generated legal content through a multi-stage classification pipeline.

## Overview

This system addresses the critical challenge of identifying factual inaccuracies (hallucinations) in legal text generated by Large Language Models. The solution employs a four-module architecture combining classification, search-based verification, and embedding-based analysis to ensure legal content accuracy.

## Architecture

### Module Pipeline

**1. First Stage Classification**
- **Purpose**: Filters paragraphs requiring fact-checking
- **Input**: Legal paragraph text
- **Output**: Binary classification (needs check / doesn't need check)
- **Training**: Supervised learning with labeled paragraph data

**2. Search Query Generator**
- **Purpose**: Generates targeted search queries for verification
- **Input**: Paragraphs flagged for checking
- **Output**: Optimized search queries for fact verification
- **Method**: Few-shot learning with LLM guidance

**3. Data Retriever**
- **Purpose**: Retrieves supporting evidence from external sources
- **Input**: Generated search queries
- **Output**: Top 5 relevant search results via Google API
- **Function**: Automated evidence collection

**4. Final Classification**
- **Purpose**: Determines presence of hallucinations using grounding data
- **Input**: Original paragraph + retrieved evidence
- **Output**: Hallucination probability score or binary classification
- **Technology**: VoyageAI embeddings (up to 25K tokens per sample)

## Dataset

### Data Composition
- **Total Samples**: 519 paragraphs
- **Sources**: Legal students, law firms, legal examinations
- **LLM Sources**: ChatGPT, Claude, Gemini, GROK
- **Verification**: Manual labeling against Israeli law and court rulings

### Data Distribution
| Category | Count | Percentage |
|----------|-------|------------|
| **Total Paragraphs** | 519 | 100% |
| **Requiring Check** | 391 | 75.3% |
| **Not Requiring Check** | 128 | 24.7% |
| **Contains Hallucination** | 192/391 | 49.1% |
| **No Hallucination** | 199/391 | 50.9% |
| **Search Queries Generated** | 391/391 | 100% |

## Performance Results

### ðŸŽ¯ Primary Model Performance
```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                        FINAL TEST RESULTS                        
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

                    Accuracy: 91.53%
                    ROC-AUC:  95.98%

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

### ðŸ“Š K-Fold Cross-Validation Results
```
Cross-Validation Accuracy: 82.84% Â± 5.15%
Cross-Validation ROC-AUC:  91.90% Â± 1.83%
Final Test Accuracy:       86.44%
Final Test ROC-AUC:        94.14%
```

## Evaluation on Most Challenging Legal Examples

Performance comparison on **96 exceptionally difficult legal samples** that require sophisticated legal understanding and nuanced analysis - representing the most challenging verification scenarios:

| Model | Type | Accuracy (%) | F1 Score |
|-------|------|--------------|----------|
| **K-Fold (threshold 0.1)** | **Our Model** | **70.00** | **0.68** |
| **K-Fold (threshold 0.5)** | **Our Model** | **63.86** | **0.57** |
| **Regular Classifier** | **Our Model** | **56.63** | **0.40** |
| GPT-4o (web access) | *Baseline* | 58.00 | 0.09 |
| Grok3 (web access) | *Baseline* | 56.00 | 0.40 |
| GPT-4o (no web access) | *Baseline* | 55.00 | 0.04 |
| DictaLM 2.0 | *Baseline* | 44.80 | 0.56 |

## Key Findings

### Model Strengths
- **First Stage Classifier**: Achieved near-perfect performance in filtering relevant paragraphs
- **Search Query Generation**: Successfully captures main paragraph concepts through few-shot learning
- **Data Retrieval**: Effectively retrieves relevant verification data
- **Embedding Quality**: VoyageAI API generates meaningful representations for legal content

### Optimization Insights
- **Threshold Sensitivity**: K-Fold model performance significantly improved with optimized threshold (0.1 vs 0.5)
- **Overfitting Mitigation**: K-Fold ensemble approach proved more robust against overfitting compared to regular classifier
- **Baseline Comparison**: State-of-the-art LLMs showed poor performance due to classification bias issues

## Technical Implementation

### Technologies Used
- **Embeddings**: VoyageAI API for text representation
- **Search**: Google API for evidence retrieval
- **Classification**: Custom neural networks with embedding inputs
- **Validation**: K-Fold cross-validation for robust evaluation

### Data Processing
- Legal text segmentation into analyzable paragraphs
- Manual expert annotation for ground truth establishment
- Automated search query generation using few-shot prompting
- Comprehensive embedding generation for semantic analysis

## Conclusion

The system demonstrates strong performance in detecting hallucinations in legal AI-generated content, with the K-Fold ensemble model achieving 70% accuracy and 0.68 F1 score on challenging evaluation samples. The multi-stage approach effectively combines automated filtering, evidence retrieval, and embedding-based classification to provide reliable hallucination detection for legal applications.

## Running the Hallucination Detector Pipeline

The hallucination detector pipeline provides a comprehensive framework for analyzing legal text and identifying potential factual inaccuracies (hallucinations).

### Pipeline Structure

The `hallucination_detector_pipeline.py` module serves as the main entry point to the system, orchestrating all components:

1. **Text Partitioning**: Splits input text into paragraphs for analysis
2. **First-Stage Classification**: Filters paragraphs to identify which require fact-checking
3. **Search Query Generation**: Creates optimized search queries for paragraphs needing verification
4. **Data Retrieval**: Retrieves evidence from external sources via Google Search API
5. **Embedding Generation**: Creates vector representations of paragraphs and search results
6. **Final Classification**: Determines presence of hallucinations by comparing embeddings

### Prerequisites

Before running the pipeline, ensure you have:

1. **Environment Setup**
   - Python 3.8+ installed
   - Virtual environment created and activated
   - Required packages installed: `pip install -r requirements.txt`

2. **API Keys**
   Create a `.env` file in the project root with the following keys:
   ```
   OPENAI_API_KEY=your_openai_api_key
   SEARCH_API_KEY=your_google_search_api_key
   SEARCH_ENGINE_ID=your_search_engine_id
   API_KEY=your_voyageai_api_key
   HUGGINGFACE_TOKEN=your_huggingface_token
   ```

3. **Model Files**
   Ensure you have the classifier models in the project root:
   - `simple_model.pth` (default - can be found in our repository)
   - `k_fold_model.pth` (optional, for improved accuracy - can be found in our repository)
   - `aleph_bert_finetuned/` directory containing the first-stage classifier model. 
    link to download this classifier: https://drive.google.com/drive/folders/1rsRUuh6JDLb8GiAbZ5HGaQmb0r-YR-FJ?usp=sharing

### Running the Pipeline

#### Model Selection

**Important**: By default, the pipeline runs with the `simple_model.pth`. For better accuracy (especially on challenging texts), you can explicitly specify the `k_fold_model.pth` model.

#### Method 1: Process a Text File

Run the pipeline on a specific legal text file:

```bash
python hallucination_detector_pipeline.py path/to/your/legal_text.txt
```

Optionally specify the k-fold model:

```bash
python hallucination_detector_pipeline.py path/to/your/legal_text.txt k_fold_model.pth
```

#### Method 2: Interactive Mode

Run in interactive mode to analyze text entered directly:

```bash
python hallucination_detector_pipeline.py
```

In this mode:
- Enter text directly when prompted
- Press Enter twice to finish input
- Type 'exit' to quit
- Choose whether to save the report after analysis

### Output

The pipeline generates:

1. A detailed console report showing:
   - Summary statistics
   - Analysis of each paragraph
   - Hallucination detections with confidence scores

2. A text file report saved with timestamp and model information:
   - Example: `test_legal_text_1_simple_model_hallucination_report_20250719_140535.txt`

### Example

Here's an example workflow:

1. Activate your environment:
   ```bash
   source venv/bin/activate  # On macOS/Linux
   ```

2. Run the pipeline on a test file using the simple model by default:
   ```bash
   python hallucination_detector_pipeline.py test_legal_text_1.txt
   ```

3. Review the generated report in both console output and the saved file.

4. For better accuracy, run with the k-fold model:
   ```bash
   python hallucination_detector_pipeline.py test_legal_text_1.txt k_fold_model.pth
   ```

---


*This project addresses the critical need for accuracy verification in AI-generated legal content, providing a scalable solution for legal professionals and AI systems requiring factual reliability.*

# Legal Text Hallucination Detection System

An Applied Natural Language Processing project focused on detecting hallucinations in AI-generated legal content through a multi-stage classification pipeline.

## Overview

This system addresses the critical challenge of identifying factual inaccuracies (hallucinations) in legal text generated by Large Language Models. The solution employs a four-module architecture combining classification, search-based verification, and embedding-based analysis to ensure legal content accuracy.

## Architecture

### Module Pipeline

**1. First Stage Classification**
- **Purpose**: Filters paragraphs requiring fact-checking
- **Input**: Legal paragraph text
- **Output**: Binary classification (needs check / doesn't need check)
- **Training**: Supervised learning with labeled paragraph data

**2. Search Query Generator**
- **Purpose**: Generates targeted search queries for verification
- **Input**: Paragraphs flagged for checking
- **Output**: Optimized search queries for fact verification
- **Method**: Few-shot learning with LLM guidance

**3. Data Retriever**
- **Purpose**: Retrieves supporting evidence from external sources
- **Input**: Generated search queries
- **Output**: Top 5 relevant search results via Google API
- **Function**: Automated evidence collection

**4. Final Classification**
- **Purpose**: Determines presence of hallucinations using grounding data
- **Input**: Original paragraph + retrieved evidence
- **Output**: Hallucination probability score or binary classification
- **Technology**: VoyageAI embeddings (up to 25K tokens per sample)

## Dataset

### Data Composition
- **Total Samples**: 519 paragraphs
- **Sources**: Legal students, law firms, legal examinations
- **LLM Sources**: ChatGPT, Claude, Gemini, GROK
- **Verification**: Manual labeling against Israeli law and court rulings

### Data Distribution
| Category | Count | Percentage |
|----------|-------|------------|
| **Total Paragraphs** | 519 | 100% |
| **Requiring Check** | 391 | 75.3% |
| **Not Requiring Check** | 128 | 24.7% |
| **Contains Hallucination** | 192/391 | 49.1% |
| **No Hallucination** | 199/391 | 50.9% |
| **Search Queries Generated** | 391/391 | 100% |

## Performance Results

### ðŸŽ¯ Primary Model Performance
```
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                        FINAL TEST RESULTS                        
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

                    Accuracy: 91.53%
                    ROC-AUC:  95.98%

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

### ðŸ“Š K-Fold Cross-Validation Results
```
Cross-Validation Accuracy: 82.84% Â± 5.15%
Cross-Validation ROC-AUC:  91.90% Â± 1.83%
Final Test Accuracy:       86.44%
Final Test ROC-AUC:        94.14%
```

## Evaluation on Most Challenging Legal Examples

Performance comparison on **96 exceptionally difficult legal samples** that require sophisticated legal understanding and nuanced analysis - representing the most challenging verification scenarios:

| Model | Type | Accuracy (%) | F1 Score |
|-------|------|--------------|----------|
| **K-Fold (threshold 0.1)** | **Our Model** | **70.00** | **0.68** |
| **K-Fold (threshold 0.5)** | **Our Model** | **63.86** | **0.57** |
| **Regular Classifier** | **Our Model** | **56.63** | **0.40** |
| GPT-4o (web access) | *Baseline* | 58.00 | 0.09 |
| Grok3 (web access) | *Baseline* | 56.00 | 0.40 |
| GPT-4o (no web access) | *Baseline* | 55.00 | 0.04 |
| DictaLM 2.0 | *Baseline* | 44.80 | 0.56 |

## Key Findings

### Model Strengths
- **First Stage Classifier**: Achieved near-perfect performance in filtering relevant paragraphs
- **Search Query Generation**: Successfully captures main paragraph concepts through few-shot learning
- **Data Retrieval**: Effectively retrieves relevant verification data
- **Embedding Quality**: VoyageAI API generates meaningful representations for legal content

### Optimization Insights
- **Threshold Sensitivity**: K-Fold model performance significantly improved with optimized threshold (0.1 vs 0.5)
- **Overfitting Mitigation**: K-Fold ensemble approach proved more robust against overfitting compared to regular classifier
- **Baseline Comparison**: State-of-the-art LLMs showed poor performance due to classification bias issues

## Technical Implementation

### Technologies Used
- **Embeddings**: VoyageAI API for text representation
- **Search**: Google API for evidence retrieval
- **Classification**: Custom neural networks with embedding inputs
- **Validation**: K-Fold cross-validation for robust evaluation

### Data Processing
- Legal text segmentation into analyzable paragraphs
- Manual expert annotation for ground truth establishment
- Automated search query generation using few-shot prompting
- Comprehensive embedding generation for semantic analysis

## Conclusion

The system demonstrates strong performance in detecting hallucinations in legal AI-generated content, with the K-Fold ensemble model achieving 70% accuracy and 0.68 F1 score on challenging evaluation samples. The multi-stage approach effectively combines automated filtering, evidence retrieval, and embedding-based classification to provide reliable hallucination detection for legal applications.

---

*This project addresses the critical need for accuracy verification in AI-generated legal content, providing a scalable solution for legal professionals and AI systems requiring factual reliability.*
